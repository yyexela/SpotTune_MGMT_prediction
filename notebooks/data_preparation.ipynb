{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d8289d-b45d-4385-8798-5e9c7cf78f83",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "The purpose of this notebook is to create the npy files that will be used for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdb6a41-f65b-422a-8937-6574bd89932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext tensorboard\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4b7199-b10e-4f05-aed5-5187e91ed955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ee577/Git/SpotTune_modified\n",
      "/home/ee577/Git\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import OrderedDict\n",
    "import SimpleITK as sitk\n",
    "#import logging\n",
    "#logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "\n",
    "import pickle, subprocess\n",
    "import scipy\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "pkg_path = str(Path(os.path.abspath('')).parent.absolute())\n",
    "print(pkg_path)\n",
    "sys.path.insert(0, pkg_path)\n",
    "pkg_path = str('/home/ee577/project')\n",
    "sys.path.insert(0, pkg_path)\n",
    "\n",
    "from src import *\n",
    "\n",
    "# Load config file\n",
    "config = global_config.config\n",
    "\n",
    "#import initial_ml as iml\n",
    "import data_prep as dp\n",
    "from pytorch.run_model_torch import RunModel\n",
    "from pytorch import resnet_spottune as rs\n",
    "from MedicalNet.models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672bda66-fb93-4df7-bac8-c2cf351b9c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "print(f\"using {device} device\")\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4335e14f-286e-44bb-8a37-831cb3d38990",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making  /home/ee577/project/Datasets/UPENN_GBM/numpy_conversion_struct_channels\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m patients \u001b[38;5;241m=\u001b[39m dp\u001b[38;5;241m.\u001b[39mretrieve_patients(csv_dir, image_dir, modality\u001b[38;5;241m=\u001b[39mmodality, classifier\u001b[38;5;241m=\u001b[39mclassifier)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#image_df = dp.retrieve_image_data(patients, modality=modality, image_dir_=image_dir)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m path_df \u001b[38;5;241m=\u001b[39m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_image_data_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderivatives\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodality\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mimage_dir_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mimage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautosegm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m#scale_file=scale_file,\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m140\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m172\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m164\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpad_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m86\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m86\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m#window=(64, 80, 60),\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbase_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m155\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m240\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m240\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownsample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mwindow_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m140\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m39\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m211\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m44\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m208\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdown_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                \u001b[49m\u001b[43maugments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Git/SpotTune_modified/data_prep.py:513\u001b[0m, in \u001b[0;36mconvert_image_data_mod\u001b[0;34m(patient_df, modality, image_dir_, out_dir, image_type, scale_file, window, pad_window, base_dim, downsample, window_idx, down_factor, augments, do_all)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f1 \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 513\u001b[0m         structural_paths\u001b[38;5;241m.\u001b[39mappend(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf1\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m         structural_paths\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(r, f1))\n",
      "File \u001b[0;32m<frozen posixpath>:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
      "File \u001b[0;32m<frozen genericpath>:164\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'list'"
     ]
    }
   ],
   "source": [
    "csv_dir = '/home/ee577/project/Datasets/UPENN_GBM/radiomic_features_CaPTk/'\n",
    "image_dir = '/home/ee577/project/Datasets/UPENN_GBM/PKG-UPENN-GBM-NIfTI/UPENN-GBM/NIfTI-files'\n",
    "\n",
    "# The modality to create npy files out of. The numpy file will have a different derivative at each index\n",
    "modality = 'struct'\n",
    "#modality = 'DSC'\n",
    "#modality = 'DTI'\n",
    "\n",
    "# The output directory of the npy files\n",
    "out_dir = os.path.join(config.upenn_dir, f'numpy_conversion_{modality}_channels')\n",
    "\n",
    "# Specify the derivatives to put into the npy file, this corresponds to the order of the derivatives when using 'channel_idx' as a reference in the training notebook\n",
    "derivatives = {\n",
    "    'struct': ['T2', 'FLAIR', 'T1', 'T1GD'],\n",
    "    'DTI':  ['DTI_AD', 'DTI_FA', 'DTI_RD', 'DTI_TR'],\n",
    "    'DSC':['DSC_ap-rCBV', 'DSC_PH', 'DSC_PSR'],\n",
    "}\n",
    "#scale_file = 'image_scaling_'+modality+'.json'\n",
    "\n",
    "#auto_df, man_df, comb_df = dp.retrieve_data(csv_dir, modality=modality)\n",
    "#patients = pd.DataFrame(auto_df.iloc[:, 0:2])\n",
    "#classifier = 'Survival_from_surgery_days'\n",
    "classifier = 'MGMT'\n",
    "patients = dp.retrieve_patients(csv_dir, image_dir, modality=modality, classifier=classifier)\n",
    "\n",
    "#image_df = dp.retrieve_image_data(patients, modality=modality, image_dir_=image_dir)\n",
    "path_df = dp.convert_image_data_mod(patients, modality=derivatives[modality], \n",
    "                                image_dir_=image_dir, out_dir=out_dir,\n",
    "                                image_type='autosegm',\n",
    "                                #scale_file=scale_file,\n",
    "                                window=(140, 172, 164),\n",
    "                                pad_window=(70, 86, 86),\n",
    "                                #window=(64, 80, 60),\n",
    "                                base_dim=(155, 240, 240), downsample=True,\n",
    "                                window_idx = ((0, 140), (39, 211), (44,208)), down_factor=0.5,\n",
    "                                augments = ('base'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee577",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
